{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqSAmqcItMXe",
    "outputId": "f1d29b56-09ab-4df0-996d-b4ab15a394d0"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5b8GgARdtSY",
    "outputId": "1ef8b557-e0ab-4989-e1bd-bb714ba69b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Copying data from Drive...\n",
      "Unzipping data...\n",
      "replace /content/data/main/0024miih-0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Done! Training data is now at: /content/data/main/train/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Mount your Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Define the path to your zip file on Drive\n",
    "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/NUS/Y3S1/CS4243/Mini Project/OCRCaptcha/data.zip\"\n",
    "LOCAL_DATA_PATH = \"/content/data/\"\n",
    "\n",
    "# 3. Copy the zip file from Drive to Colab's fast local disk\n",
    "print(\"Copying data from Drive...\")\n",
    "!cp \"{DRIVE_ZIP_PATH}\" /content/\n",
    "\n",
    "# 4. Unzip the data quietly\n",
    "print(\"Unzipping data...\")\n",
    "!unzip -q /content/data.zip -d /content/\n",
    "\n",
    "# 5. Set your global paths to use the NEW local directory\n",
    "train_data_path = os.path.join(LOCAL_DATA_PATH, \"main/train/\")\n",
    "test_data_path = os.path.join(LOCAL_DATA_PATH, \"main/test/\")\n",
    "MODEL_PATH = 'models/best_crnn_model.keras'\n",
    "\n",
    "# 6. Make a local 'models' folder\n",
    "!mkdir -p models\n",
    "\n",
    "print(f\"Done! Training data is now at: {train_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAy_2ID3biHD",
    "outputId": "f06f057a-adb3-415c-9cb9-5f84f7005a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 36, Max length: 8\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# === 1. LOAD CONSTANTS ===\n",
    "# Load paths and labels\n",
    "train_image_paths = sorted(glob.glob(os.path.join(train_data_path, \"*.png\")))\n",
    "train_labels = [os.path.basename(path).split('-')[0] for path in train_image_paths]\n",
    "test_paths = sorted(glob.glob(os.path.join(test_data_path, \"*.png\")))\n",
    "test_labels = [os.path.basename(path).split('-')[0] for path in test_paths]\n",
    "\n",
    "# Get vocab and max length\n",
    "all_labels = train_labels + test_labels\n",
    "all_characters = set(char for label in all_labels for char in label)\n",
    "vocabulary = sorted(list(all_characters))\n",
    "max_label_len = max(len(label) for label in all_labels)\n",
    "IMG_HEIGHT = 50\n",
    "IMG_WIDTH = 495\n",
    "\n",
    "# Create mapping (Index 0 is for CTC 'blank' token)\n",
    "char_to_num = {char: i + 1 for i, char in enumerate(vocabulary)}\n",
    "num_to_char = {i + 1: char for i, char in enumerate(vocabulary)}\n",
    "\n",
    "print(f\"Vocab size: {len(vocabulary)}, Max length: {max_label_len}\")\n",
    "\n",
    "\n",
    "# === 2. PREPROCESSING FUNCTION (UPDATED with Denoising) ===\n",
    "def prepare_image_for_crnn(image_path, img_width=IMG_WIDTH, img_height=IMG_HEIGHT):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # --- ADDED: Denoise BEFORE enhancing contrast ---\n",
    "    img = cv2.medianBlur(img, 3)\n",
    "\n",
    "    # 1. CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img)\n",
    "\n",
    "    # 2. Adaptive Thresholding\n",
    "    img = cv2.adaptiveThreshold(\n",
    "        img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 15, 3\n",
    "    )\n",
    "\n",
    "    # 3. Morphological Opening\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 4. Resize\n",
    "    h, w = img.shape\n",
    "    scale = img_height / h\n",
    "    new_w = int(w * scale)\n",
    "    if new_w > img_width:\n",
    "        new_w = img_width\n",
    "    img = cv2.resize(img, (new_w, img_height))\n",
    "\n",
    "    # 5. Pad\n",
    "    target = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "    target[:, :new_w] = img\n",
    "\n",
    "    # 6. Normalize\n",
    "    img_float = target.astype(np.float32) / 255.0\n",
    "\n",
    "    # 7. Transpose\n",
    "    img_transposed = np.transpose(img_float, (1, 0))\n",
    "\n",
    "    # 8. Add channel dimension\n",
    "    img_final = np.expand_dims(img_transposed, axis=-1)\n",
    "\n",
    "    return img_final\n",
    "\n",
    "\n",
    "# === 3. CTC LOSS FUNCTION (FIXED) ===\n",
    "def ctc_loss_function(y_true, y_pred):\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    pred_length = tf.shape(y_pred)[1]\n",
    "\n",
    "    # FIX: Count non-padding (non-zero) tokens\n",
    "    label_lengths = tf.reduce_sum(tf.cast(y_true > 0, dtype=\"int32\"), axis=1)\n",
    "\n",
    "    input_lengths = tf.fill([batch_size], pred_length)\n",
    "\n",
    "    # FIX: No need to clean, just cast. 0 is the blank index.\n",
    "    y_true_clean = tf.cast(y_true, dtype=\"int32\")\n",
    "\n",
    "    loss = tf.nn.ctc_loss(\n",
    "        labels=y_true_clean,\n",
    "        logits=y_pred,\n",
    "        label_length=label_lengths,\n",
    "        logit_length=input_lengths,\n",
    "        logits_time_major=False,\n",
    "        blank_index=0\n",
    "    )\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# === 4. DECODE FUNCTION ===\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = K.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = result.numpy()\n",
    "        text = ''.join([num_to_char.get(int(idx), '') for idx in result if int(idx) != 0])\n",
    "        output_text.append(text)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# === 5. DATA GENERATOR (FIXED for Keras 3 - Augmentation Removed) ===\n",
    "class CaptchaDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, labels, char_to_num,\n",
    "                 img_width, img_height, batch_size,\n",
    "                 max_label_length, shuffle=True, **kwargs): # <-- REMOVED is_training\n",
    "\n",
    "        super().__init__(**kwargs) # <-- Pass kwargs to super\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.char_to_num = char_to_num\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.batch_size = batch_size\n",
    "        self.max_label_length = max_label_length\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_paths = [self.image_paths[k] for k in batch_indexes]\n",
    "        batch_labels = [self.labels[k] for k in batch_indexes]\n",
    "        X, y = self.__data_generation(batch_paths, batch_labels)\n",
    "        return X, y\n",
    "\n",
    "    def __data_generation(self, batch_paths, batch_labels):\n",
    "        X = np.zeros((self.batch_size, self.img_width, self.img_height, 1), dtype=np.float32)\n",
    "        y = np.zeros((self.batch_size, self.max_label_length), dtype=np.int32)\n",
    "\n",
    "        for i, (img_path, label) in enumerate(zip(batch_paths, batch_labels)):\n",
    "            img = prepare_image_for_crnn(img_path, self.img_width, self.img_height)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            # --- AUGMENTATION REMOVED FROM HERE ---\n",
    "            X[i] = img\n",
    "\n",
    "            encoded_label = [self.char_to_num[char] for char in label]\n",
    "            padded_label = encoded_label + [0] * (self.max_label_length - len(encoded_label))\n",
    "            y[i] = padded_label[:self.max_label_length]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# === 6. MODEL CLASS (FIXED - Augmentation Added to Model) ===\n",
    "\n",
    "# --- DATA AUGMENTATION (Moved from bottom) ---\n",
    "# Define a small augmentation pipeline\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomRotation(factor=0.02, fill_mode='constant', fill_value=0.0),\n",
    "    layers.RandomTranslation(height_factor=0.05, width_factor=0.05, fill_mode='constant', fill_value=0.0),\n",
    "    layers.RandomZoom(height_factor=0.05, width_factor=0.05, fill_mode='constant', fill_value=0.0)\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "\n",
    "class CRNNCaptchaModel(keras.Model):\n",
    "    def __init__(self, img_width, img_height, vocab_size):\n",
    "        super().__init__()\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.vocab_size = vocab_size\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        regularizer = keras.regularizers.l2(1e-5)\n",
    "\n",
    "        input_img = layers.Input(\n",
    "            shape=(self.img_width, self.img_height, 1),\n",
    "            name='image', dtype='float32'\n",
    "        )\n",
    "\n",
    "        # --- AUGMENTATION ADDED HERE ---\n",
    "        # Apply augmentation only during training\n",
    "        x = data_augmentation(input_img)\n",
    "        # The line above is a shortcut. A more robust way is:\n",
    "        # x = keras.layers.Layer(lambda inputs, training=False: data_augmentation(inputs) if training else inputs)(input_img)\n",
    "        # But for this model, applying it always is fine and simpler.\n",
    "        # If val_loss is weird, we can switch to the more robust way.\n",
    "\n",
    "        # --- Apply regularizer to Conv layers ---\\\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1', kernel_regularizer=regularizer)(x)\n",
    "        x = layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2', kernel_regularizer=regularizer)(x)\n",
    "        x = layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3', kernel_regularizer=regularizer)(x)\n",
    "        x = layers.BatchNormalization(name='bn1')(x)\n",
    "        x = layers.MaxPooling2D((2, 1), name='pool3')(x)\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv4', kernel_regularizer=regularizer)(x)\n",
    "        x = layers.BatchNormalization(name='bn2')(x)\n",
    "        x = layers.MaxPooling2D((2, 1), name='pool4')(x)\n",
    "        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv5', kernel_regularizer=regularizer)(x)\n",
    "        x = layers.BatchNormalization(name='bn3')(x)\n",
    "\n",
    "        conv_output_shape = x.shape\n",
    "        conv_output_width = conv_output_shape[1]\n",
    "        new_features = conv_output_shape[2] * conv_output_shape[3]\n",
    "        x = layers.Reshape(target_shape=(conv_output_width, new_features), name='reshape')(x)\n",
    "        x = layers.Dropout(0.4, name='dropout_after_reshape')(x)\n",
    "        x = layers.Bidirectional(\n",
    "            layers.LSTM(128, return_sequences=True, dropout=0.25),\n",
    "            name='bidirectional_lstm_1'\n",
    "        )(x)\n",
    "        x = layers.Bidirectional(\n",
    "            layers.LSTM(64, return_sequences=True, dropout=0.25),\n",
    "            name='bidirectional_lstm_2'\n",
    "        )(x)\n",
    "        output = layers.Dense(\n",
    "            self.vocab_size + 1,\n",
    "            activation=None,\n",
    "            name='output',\n",
    "            kernel_regularizer=regularizer\n",
    "        )(x)\n",
    "\n",
    "        self.model = keras.models.Model(inputs=input_img, outputs=output, name='CRNN_CAPTCHA')\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    def train(self, train_generator, val_generator, epochs, callbacks):\n",
    "        history = self.model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "# === 7. DATA AUGMENTATION ===\n",
    "# This block is now defined UPSTREAM, before the model class.\n",
    "# This cell will just be comments.\n",
    "# data_augmentation = keras.Sequential([...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j92qI0xAbm0e",
    "outputId": "1a674bde-d8bb-422e-9c51-0a281898b48a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CRNN_CAPTCHA\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CRNN_CAPTCHA\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_after_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_lstm_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,824</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_lstm_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,773</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m495\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m495\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m495\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m247\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m247\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv4 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv5 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bn3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3072\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_after_reshape (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3072\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_lstm_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m3,277,824\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_lstm_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m37\u001b[0m)         │         \u001b[38;5;34m4,773\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,984,421</span> (15.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,984,421\u001b[0m (15.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,983,397</span> (15.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,983,397\u001b[0m (15.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING TRAINING...\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 26.5583\n",
      "Epoch 1: val_loss improved from inf to 27.82182, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 166ms/step - loss: 26.5469 - val_loss: 27.8218 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 23.2798\n",
      "Epoch 2: val_loss did not improve from 27.82182\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 165ms/step - loss: 23.2796 - val_loss: 58.4498 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 22.6191\n",
      "Epoch 3: val_loss improved from 27.82182 to 21.01328, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 161ms/step - loss: 22.6161 - val_loss: 21.0133 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 19.6335\n",
      "Epoch 4: val_loss improved from 21.01328 to 17.84457, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 164ms/step - loss: 19.6298 - val_loss: 17.8446 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 16.7400\n",
      "Epoch 5: val_loss improved from 17.84457 to 15.79355, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 156ms/step - loss: 16.7370 - val_loss: 15.7935 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 14.3821\n",
      "Epoch 6: val_loss improved from 15.79355 to 13.48091, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - loss: 14.3799 - val_loss: 13.4809 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 12.4748\n",
      "Epoch 7: val_loss improved from 13.48091 to 11.94190, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 164ms/step - loss: 12.4743 - val_loss: 11.9419 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 11.6392\n",
      "Epoch 8: val_loss improved from 11.94190 to 10.90466, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - loss: 11.6381 - val_loss: 10.9047 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 10.9526\n",
      "Epoch 9: val_loss did not improve from 10.90466\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 163ms/step - loss: 10.9516 - val_loss: 11.3533 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 10.2436\n",
      "Epoch 10: val_loss improved from 10.90466 to 9.43217, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 155ms/step - loss: 10.2431 - val_loss: 9.4322 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 9.8971\n",
      "Epoch 11: val_loss improved from 9.43217 to 8.93065, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - loss: 9.8969 - val_loss: 8.9306 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 9.3790\n",
      "Epoch 12: val_loss did not improve from 8.93065\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 155ms/step - loss: 9.3793 - val_loss: 9.6159 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 9.2532\n",
      "Epoch 13: val_loss did not improve from 8.93065\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - loss: 9.2532 - val_loss: 9.1650 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 8.9746\n",
      "Epoch 14: val_loss improved from 8.93065 to 8.75076, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 155ms/step - loss: 8.9746 - val_loss: 8.7508 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 8.8332\n",
      "Epoch 15: val_loss did not improve from 8.75076\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 161ms/step - loss: 8.8330 - val_loss: 9.4730 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 8.7138\n",
      "Epoch 16: val_loss did not improve from 8.75076\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 159ms/step - loss: 8.7134 - val_loss: 49.0307 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 8.5571\n",
      "Epoch 17: val_loss improved from 8.75076 to 8.15433, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 159ms/step - loss: 8.5567 - val_loss: 8.1543 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 8.3812\n",
      "Epoch 18: val_loss did not improve from 8.15433\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 162ms/step - loss: 8.3810 - val_loss: 23.7659 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 8.3011\n",
      "Epoch 19: val_loss improved from 8.15433 to 8.11452, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - loss: 8.3006 - val_loss: 8.1145 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.1267\n",
      "Epoch 20: val_loss did not improve from 8.11452\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 163ms/step - loss: 8.1265 - val_loss: 8.1803 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 7.9916\n",
      "Epoch 21: val_loss improved from 8.11452 to 7.95094, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - loss: 7.9916 - val_loss: 7.9509 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.9982\n",
      "Epoch 22: val_loss improved from 7.95094 to 7.85824, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - loss: 7.9977 - val_loss: 7.8582 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 7.9246\n",
      "Epoch 23: val_loss improved from 7.85824 to 7.73220, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 164ms/step - loss: 7.9240 - val_loss: 7.7322 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 7.5814\n",
      "Epoch 24: val_loss improved from 7.73220 to 7.50016, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 158ms/step - loss: 7.5818 - val_loss: 7.5002 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 7.6143\n",
      "Epoch 25: val_loss did not improve from 7.50016\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 163ms/step - loss: 7.6142 - val_loss: 8.8494 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 7.5799\n",
      "Epoch 26: val_loss did not improve from 7.50016\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 155ms/step - loss: 7.5798 - val_loss: 7.6313 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.5160\n",
      "Epoch 27: val_loss did not improve from 7.50016\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - loss: 7.5157 - val_loss: 25.4662 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 7.6735\n",
      "Epoch 28: val_loss improved from 7.50016 to 7.26136, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 156ms/step - loss: 7.6726 - val_loss: 7.2614 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 7.2884\n",
      "Epoch 29: val_loss did not improve from 7.26136\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 162ms/step - loss: 7.2884 - val_loss: 8.0325 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 7.3693\n",
      "Epoch 30: val_loss did not improve from 7.26136\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 156ms/step - loss: 7.3690 - val_loss: 7.4221 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.1561\n",
      "Epoch 31: val_loss did not improve from 7.26136\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 159ms/step - loss: 7.1564 - val_loss: 7.4662 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 7.1807\n",
      "Epoch 32: val_loss did not improve from 7.26136\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 159ms/step - loss: 7.1806 - val_loss: 7.5785 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 7.1714\n",
      "Epoch 33: val_loss did not improve from 7.26136\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 156ms/step - loss: 7.1715 - val_loss: 7.6291 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 6.8606\n",
      "Epoch 34: val_loss improved from 7.26136 to 7.08188, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 166ms/step - loss: 6.8604 - val_loss: 7.0819 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 6.7016\n",
      "Epoch 35: val_loss improved from 7.08188 to 7.05596, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - loss: 6.7016 - val_loss: 7.0560 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.6620\n",
      "Epoch 36: val_loss improved from 7.05596 to 7.01446, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 165ms/step - loss: 6.6619 - val_loss: 7.0145 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 6.6407\n",
      "Epoch 37: val_loss improved from 7.01446 to 6.91680, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - loss: 6.6406 - val_loss: 6.9168 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 6.4439\n",
      "Epoch 38: val_loss improved from 6.91680 to 6.87660, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 162ms/step - loss: 6.4440 - val_loss: 6.8766 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 6.3981\n",
      "Epoch 39: val_loss did not improve from 6.87660\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 156ms/step - loss: 6.3984 - val_loss: 6.9595 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 6.4985\n",
      "Epoch 40: val_loss did not improve from 6.87660\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 159ms/step - loss: 6.4986 - val_loss: 6.8949 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 6.5389\n",
      "Epoch 41: val_loss did not improve from 6.87660\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 163ms/step - loss: 6.5385 - val_loss: 6.9393 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 6.3559\n",
      "Epoch 42: val_loss improved from 6.87660 to 6.79823, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 158ms/step - loss: 6.3561 - val_loss: 6.7982 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 6.3697\n",
      "Epoch 43: val_loss did not improve from 6.79823\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 162ms/step - loss: 6.3696 - val_loss: 6.8162 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 6.3122\n",
      "Epoch 44: val_loss did not improve from 6.79823\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - loss: 6.3119 - val_loss: 6.8359 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 6.2520\n",
      "Epoch 45: val_loss did not improve from 6.79823\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 162ms/step - loss: 6.2522 - val_loss: 6.8501 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 6.3171\n",
      "Epoch 46: val_loss improved from 6.79823 to 6.74161, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 158ms/step - loss: 6.3169 - val_loss: 6.7416 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 6.2562\n",
      "Epoch 47: val_loss improved from 6.74161 to 6.69827, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 161ms/step - loss: 6.2562 - val_loss: 6.6983 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 6.1030\n",
      "Epoch 48: val_loss did not improve from 6.69827\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 155ms/step - loss: 6.1034 - val_loss: 6.9067 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 6.1033\n",
      "Epoch 49: val_loss did not improve from 6.69827\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - loss: 6.1036 - val_loss: 6.7285 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 6.1619\n",
      "Epoch 50: val_loss improved from 6.69827 to 6.65537, saving model to models/best_crnn_model.keras\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 163ms/step - loss: 6.1620 - val_loss: 6.6554 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "TRAINING COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# === SPLIT DATA ===\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_image_paths,\n",
    "    train_labels,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === CREATE GENERATORS (UPDATED - is_training Removed) ===\n",
    "train_generator = CaptchaDataGenerator(\n",
    "    train_paths, train_labels, char_to_num,\n",
    "    IMG_WIDTH, IMG_HEIGHT, batch_size=32,\n",
    "    max_label_length=max_label_len, shuffle=True,\n",
    "    use_multiprocessing=True,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "val_generator = CaptchaDataGenerator(\n",
    "    val_paths, val_labels, char_to_num,\n",
    "    IMG_WIDTH, IMG_HEIGHT, batch_size=32,\n",
    "    max_label_length=max_label_len, shuffle=False,\n",
    "    use_multiprocessing=True,\n",
    "    workers=8\n",
    ")\n",
    "\n",
    "# === BUILD & COMPILE MODEL ===\n",
    "crnn_model = CRNNCaptchaModel(IMG_WIDTH, IMG_HEIGHT, len(vocabulary))\n",
    "crnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=ctc_loss_function\n",
    ")\n",
    "crnn_model.get_model().summary()\n",
    "\n",
    "# === CALLBACKS ===\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
    ")\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_PATH, monitor='val_loss', save_best_only=True, verbose=1\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "# === START TRAINING (Original call) ===\n",
    "print(\"\\nSTARTING TRAINING...\\n\")\n",
    "history = crnn_model.train(\n",
    "    train_generator=train_generator,\n",
    "    val_generator=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
    ")\n",
    "print(\"TRAINING COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYUMJFskhtNx"
   },
   "source": [
    "STARTING TRAINING...\n",
    "Epoch 1/50\n",
    "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
    "  self._warn_if_super_not_called()\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 26.0810\n",
    "Epoch 1: val_loss improved from inf to 24.06589, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 46s 154ms/step - loss: 26.0710 - val_loss: 24.0659 - learning_rate: 0.0010\n",
    "Epoch 2/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 23.0881\n",
    "Epoch 2: val_loss improved from 24.06589 to 22.77093, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 33s 145ms/step - loss: 23.0873 - val_loss: 22.7709 - learning_rate: 0.0010\n",
    "Epoch 3/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 21.5873\n",
    "Epoch 3: val_loss improved from 22.77093 to 18.82375, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 33s 145ms/step - loss: 21.5822 - val_loss: 18.8238 - learning_rate: 0.0010\n",
    "Epoch 4/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 133ms/step - loss: 16.1739\n",
    "Epoch 4: val_loss improved from 18.82375 to 13.42686, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 143ms/step - loss: 16.1688 - val_loss: 13.4269 - learning_rate: 0.0010\n",
    "Epoch 5/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 12.1346\n",
    "Epoch 5: val_loss improved from 13.42686 to 11.25575, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 41s 143ms/step - loss: 12.1327 - val_loss: 11.2558 - learning_rate: 0.0010\n",
    "Epoch 6/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 10.2479\n",
    "Epoch 6: val_loss improved from 11.25575 to 10.20178, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 143ms/step - loss: 10.2473 - val_loss: 10.2018 - learning_rate: 0.0010\n",
    "Epoch 7/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 137ms/step - loss: 9.0712\n",
    "Epoch 7: val_loss did not improve from 10.20178\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 33s 148ms/step - loss: 9.0713 - val_loss: 10.2769 - learning_rate: 0.0010\n",
    "Epoch 8/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 8.4002\n",
    "Epoch 8: val_loss improved from 10.20178 to 9.60412, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 143ms/step - loss: 8.4002 - val_loss: 9.6041 - learning_rate: 0.0010\n",
    "Epoch 9/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 133ms/step - loss: 7.6926\n",
    "Epoch 9: val_loss improved from 9.60412 to 9.32790, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 34s 149ms/step - loss: 7.6928 - val_loss: 9.3279 - learning_rate: 0.0010\n",
    "Epoch 10/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 7.3063\n",
    "Epoch 10: val_loss improved from 9.32790 to 8.65429, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 142ms/step - loss: 7.3061 - val_loss: 8.6543 - learning_rate: 0.0010\n",
    "Epoch 11/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 6.6035\n",
    "Epoch 11: val_loss did not improve from 8.65429\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 141ms/step - loss: 6.6042 - val_loss: 9.0576 - learning_rate: 0.0010\n",
    "Epoch 12/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 134ms/step - loss: 6.0726\n",
    "Epoch 12: val_loss improved from 8.65429 to 8.48881, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 33s 148ms/step - loss: 6.0737 - val_loss: 8.4888 - learning_rate: 0.0010\n",
    "Epoch 13/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 5.8430\n",
    "Epoch 13: val_loss improved from 8.48881 to 8.44051, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 142ms/step - loss: 5.8433 - val_loss: 8.4405 - learning_rate: 0.0010\n",
    "Epoch 14/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 130ms/step - loss: 5.3896\n",
    "Epoch 14: val_loss did not improve from 8.44051\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 140ms/step - loss: 5.3902 - val_loss: 8.5640 - learning_rate: 0.0010\n",
    "Epoch 15/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 5.0965\n",
    "Epoch 15: val_loss improved from 8.44051 to 8.42459, saving model to models/best_crnn_model.keras\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 43s 150ms/step - loss: 5.0970 - val_loss: 8.4246 - learning_rate: 0.0010\n",
    "Epoch 16/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 4.7572\n",
    "Epoch 16: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 141ms/step - loss: 4.7579 - val_loss: 8.7937 - learning_rate: 0.0010\n",
    "Epoch 17/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 4.4304\n",
    "Epoch 17: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 141ms/step - loss: 4.4311 - val_loss: 8.7627 - learning_rate: 0.0010\n",
    "Epoch 18/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 133ms/step - loss: 4.2212\n",
    "Epoch 18: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 33s 147ms/step - loss: 4.2215 - val_loss: 8.9010 - learning_rate: 0.0010\n",
    "Epoch 19/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 4.0125\n",
    "Epoch 19: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 141ms/step - loss: 4.0127 - val_loss: 9.3011 - learning_rate: 0.0010\n",
    "Epoch 20/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - loss: 3.7029\n",
    "Epoch 20: val_loss did not improve from 8.42459\n",
    "\n",
    "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 41s 140ms/step - loss: 3.7033 - val_loss: 9.5020 - learning_rate: 0.0010\n",
    "Epoch 21/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 3.1940\n",
    "Epoch 21: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 35s 154ms/step - loss: 3.1935 - val_loss: 9.2582 - learning_rate: 5.0000e-04\n",
    "Epoch 22/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 2.5649\n",
    "Epoch 22: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 142ms/step - loss: 2.5653 - val_loss: 9.1584 - learning_rate: 5.0000e-04\n",
    "Epoch 23/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - loss: 2.3671\n",
    "Epoch 23: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 32s 143ms/step - loss: 2.3673 - val_loss: 9.3659 - learning_rate: 5.0000e-04\n",
    "Epoch 24/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 136ms/step - loss: 2.2004\n",
    "Epoch 24: val_loss did not improve from 8.42459\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 33s 146ms/step - loss: 2.2006 - val_loss: 9.5862 - learning_rate: 5.0000e-04\n",
    "Epoch 25/50\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 0s 137ms/step - loss: 2.0098\n",
    "Epoch 25: val_loss did not improve from 8.42459\n",
    "\n",
    "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
    "225/225 ━━━━━━━━━━━━━━━━━━━━ 41s 147ms/step - loss: 2.0101 - val_loss: 9.7527 - learning_rate: 5.0000e-04\n",
    "Epoch 25: early stopping\n",
    "Restoring model weights from the end of the best epoch: 15.\n",
    "TRAINING COMPLETE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5uccWTAYciA0",
    "outputId": "2150cefe-c7f0-49cb-ae7a-5197b408597d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === LOAD BEST MODEL ===\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m      3\u001b[0m     MODEL_PATH,\n\u001b[0;32m      4\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctc_loss_function\u001b[39m\u001b[38;5;124m'\u001b[39m: ctc_loss_function}\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Best model loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# === EVALUATION FUNCTION (MODIFIED) ===\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# === LOAD BEST MODEL ===\n",
    "loaded_model = keras.models.load_model(\n",
    "    MODEL_PATH,\n",
    "    custom_objects={'ctc_loss_function': ctc_loss_function}\n",
    ")\n",
    "print(\"✓ Best model loaded successfully!\")\n",
    "\n",
    "# === EVALUATION FUNCTION (MODIFIED) ===\n",
    "def test_multiple_from_loaded_model(num_samples=10):\n",
    "    print(f\"\\nTESTING {num_samples} RANDOM IMAGES FROM TEST SET\\n\")\n",
    "\n",
    "    test_paths_sample = random.sample(test_paths, min(num_samples, len(test_paths)))\n",
    "    results = []\n",
    "\n",
    "    # --- CHANGED: Create a plot with num_samples rows and 2 columns ---\n",
    "    fig, axes = plt.subplots(nrows=num_samples, ncols=2, figsize=(10, num_samples * 2.5))\n",
    "\n",
    "    # Handle the case of a single sample\n",
    "    if num_samples == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    for i, img_path in enumerate(test_paths_sample):\n",
    "        actual = os.path.basename(img_path).split('-')[0]\n",
    "\n",
    "        # Handle cases where image read might fail\n",
    "        try:\n",
    "            img = prepare_image_for_crnn(img_path, IMG_WIDTH, IMG_HEIGHT)\n",
    "            if img is None:\n",
    "                print(f\"Skipping {img_path}, could not be read.\")\n",
    "                continue\n",
    "\n",
    "            img_batch = np.expand_dims(img, axis=0)\n",
    "            pred = loaded_model.predict(img_batch, verbose=0)\n",
    "            predicted = decode_batch_predictions(pred)[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        is_correct = (actual == predicted)\n",
    "        results.append({'actual': actual, 'predicted': predicted, 'correct': is_correct})\n",
    "\n",
    "        # --- PLOT 1: ORIGINAL IMAGE ---\n",
    "        original_img = cv2.imread(img_path)\n",
    "        rgb_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "        ax_orig = axes[i, 0]\n",
    "        ax_orig.imshow(rgb_img)\n",
    "        ax_orig.set_title(f\"Original: {os.path.basename(img_path)}\")\n",
    "        ax_orig.axis('off')\n",
    "\n",
    "        # --- PLOT 2: PREPROCESSED IMAGE (with Title) ---\n",
    "        status = '✓' if is_correct else '✗'\n",
    "        pred_display = predicted if predicted else '(empty)'\n",
    "        title = f\"Actual: {actual} | Predicted: {pred_display} {status}\"\n",
    "        color = 'green' if is_correct else 'red'\n",
    "\n",
    "        # Undo transpose and remove channel dim for display\n",
    "        img_to_show = np.transpose(img[:, :, 0], (1, 0))\n",
    "\n",
    "        ax_proc = axes[i, 1]\n",
    "        ax_proc.imshow(img_to_show, cmap='gray')\n",
    "        ax_proc.set_title(title, color=color, fontsize=12)\n",
    "        ax_proc.axis('off')\n",
    "\n",
    "    # --- REMOVED cleanup loop as it's no longer needed ---\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary\n",
    "    correct = sum(1 for r in results if r['correct'])\n",
    "    total = len(results)\n",
    "    if total > 0:\n",
    "        print(f\"\\n{'='*70}\\nSUMMARY:\")\n",
    "        print(f\"  Correct:  {correct}/{total} ({(correct/total)*100:.1f}%)\\n{'='*70}\")\n",
    "    else:\n",
    "        print(\"No images were tested.\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# === RUN EVALUATION ===\n",
    "results = test_multiple_from_loaded_model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
